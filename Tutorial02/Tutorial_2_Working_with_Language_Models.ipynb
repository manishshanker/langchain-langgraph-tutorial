{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Working with Language Models in LangChain\n",
    "\n",
    "In this tutorial, we'll explore how to work with language models in LangChain, focusing on the Groq LLM. We'll cover connecting to the model, creating prompt templates, building chains, and handling responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connecting to Language Models\n",
    "\n",
    "First, let's set up our environment and connect to the Groq LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 39, 'total_tokens': 64, 'completion_time': 0.090909091, 'prompt_time': 0.005151586, 'queue_time': 0.107275894, 'total_time': 0.096060677}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_41c250edc7', 'finish_reason': 'stop', 'logprobs': None} id='run-e393d7a4-6395-42c1-8af8-3147425b5119-0' usage_metadata={'input_tokens': 39, 'output_tokens': 25, 'total_tokens': 64}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq LLM\n",
    "llm = ChatGroq(\n",
    "        model_name=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.1,\n",
    "        model_kwargs={\"top_p\": 0.2, \"seed\": 1337}\n",
    "    )\n",
    "\n",
    "# Test the connection\n",
    "response = llm.invoke(\"Hello, world!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Prompt Templates\n",
    "\n",
    "Prompt templates allow us to create reusable prompts with input variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question:\n",
      "You answers in the English language.\n",
      "Question: What is the capital of France?\n",
      "Answer: Let's approach this step-by-step:\n"
     ]
    }
   ],
   "source": [
    "# Define a simple prompt template\n",
    "template = \"\"\"Answer the following question:\n",
    "You answers in the {language} language.\n",
    "Question: {question}\n",
    "Answer: Let's approach this step-by-step:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\",\"language\"])\n",
    "\n",
    "# Use the prompt template\n",
    "question = \"What is the capital of France?\"\n",
    "formatted_prompt = prompt.format(question=question,language=\"English\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Simple Prompt Chains\n",
    "\n",
    "Now, let's create a chain that combines our prompt template with the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commençons par aborder cela étape par étape : \n",
      "\n",
      "1. La vitesse de la lumière est une constante physique fondamentale.\n",
      "2. Elle est représentée par la lettre c dans les équations physiques.\n",
      "3. La vitesse de la lumière dans le vide est d'environ 299 792 kilomètres par seconde.\n",
      "4. Cette vitesse est une limite supérieure pour toute vitesse dans l'univers, selon la théorie de la relativité d'Albert Einstein.\n",
      "5. La connaissance de la vitesse de la lumière est essentielle pour de nombreux domaines de la physique, notamment l'optique, l'électromagnétisme et la mécanique relativiste.\n",
      "\n",
      "La vitesse de la lumière est donc d'environ 299 792 kilomètres par seconde.\n"
     ]
    }
   ],
   "source": [
    "# Create a chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"question\":\"What is the speed of light?\",\"language\":\"French\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Model Responses\n",
    "\n",
    "Let's explore different ways to handle and process model responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: content='Here are three prime numbers: \\n1. 7\\n2. 11\\n3. 13' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 40, 'total_tokens': 62, 'completion_time': 0.08, 'prompt_time': 0.002185875, 'queue_time': 0.10951446199999999, 'total_time': 0.082185875}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34555b7c20', 'finish_reason': 'stop', 'logprobs': None} id='run-89b6bbdb-f011-46e0-b901-aa0f31f7f1e2-0' usage_metadata={'input_tokens': 40, 'output_tokens': 22, 'total_tokens': 62}\n",
      "\n",
      "Chain response: Commençons par la liste des noms d'arbres :\n",
      "1. Le chêne\n",
      "2. Le pin\n",
      "3. Le sapin\n",
      "4. Le cèdre\n",
      "5. Le cyprès\n",
      "6. L'érable\n",
      "7. Le bouleau\n",
      "8. Le peuplier\n",
      "9. Le saule\n",
      "10. Le noyer\n",
      "\n",
      "Nous pouvons également citer d'autres types d'arbres tels que :\n",
      "- Le châtaignier\n",
      "- Le marronnier\n",
      "- Le tilleul\n",
      "- Le platane\n",
      "- Le liège\n",
      "\n",
      "Il existe de nombreux autres noms d'arbres, mais cela donne une bonne idée de départ.\n"
     ]
    }
   ],
   "source": [
    "# Get the raw response\n",
    "raw_response = llm.invoke(\"List three prime numbers.\")\n",
    "print(\"Raw response:\", raw_response)\n",
    "\n",
    "# Using the chain with a dictionary input\n",
    "chain_response = chain.invoke({\"question\": \"tree Names\",\"language\": \"French\"})\n",
    "print(\"\\nChain response:\", chain_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "\n",
      "Parsed list: ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet', 'black', 'white', 'gray', 'brown', 'pink', 'turquoise', 'silver', 'gold', 'copper', 'bronze', 'crimson', 'scarlet', 'vermilion', 'magenta', 'cyan', 'teal', 'cobalt', 'navy', 'purple', 'lavender', 'peach', 'mint', 'coral', 'salmon', 'beige', 'ivory', 'cream', 'charcoal', 'periwinkle', 'turquoise', 'sage', 'sienna', 'umber', 'sepia', 'mahogany', 'walnut', 'chestnut', 'caramel', 'honey', 'mustard', 'olive', 'lime', 'forest', 'hunter', 'spruce', 'fir', 'pine', 'moss', 'fern', 'eucalyptus', 'seafoam', 'aqua', 'sky', 'powder', 'rose', 'blush', 'garnet', 'ruby', 'emerald', 'sapphire', 'amethyst', 'onyx', 'jade', 'pearl', 'opal', 'amber', 'tangerine', 'lemon', 'cherry', 'plum', 'burgundy', 'raspberry', 'fuchsia', 'lilac', 'wisteria', 'iris', 'poppy', 'sunflower', 'daffodil', 'buttercup', 'clover', 'shamrock', 'minty', 'frosty', 'icy', 'glacier', 'snowflake', 'coal', 'slate', 'granite', 'sand', 'clay', 'terracotta', 'ceramic', 'porcelain', 'ivory', 'cream', 'champagne', 'goldenrod', 'saffron', 'marigold', 'carrot', 'pumpkin', 'squash', 'peanut', 'pecan', 'hazelnut', 'caramel', 'toffee', 'butterscotch', 'cinnamon', 'ginger', 'nutmeg', 'cardamom', 'sage', 'sandalwood', 'cedar', 'pine', 'spruce', 'fir', 'cypress', 'juniper', 'bluebell', 'forget-me-not', 'cornflower', 'larkspur', 'delphinium', 'hyacinth', 'dahlia', 'zinnia', 'cosmos', 'sunflower', 'daisy', 'gerbera', 'tulip', 'lily', 'orchid', 'violet', 'pansy', 'petunia', 'begonia', 'geranium', 'hibiscus', 'passionflower', 'hollyhock', 'foxglove', 'snapdragon', 'nasturtium', 'marigold', 'calendula', 'chrysanthemum', 'aster', 'dahlia', 'zinnia', 'cosmos', 'sunflower', 'daisy', 'gerbera', 'tulip', 'lily', 'orchid', 'violet', 'pansy', 'petunia', 'begonia', 'geranium', 'hibiscus', 'passionflower', 'hollyhock', 'foxglove', 'snapdragon', 'nasturtium', 'marigold', 'calendula', 'chrysanthemum', 'aster']\n"
     ]
    }
   ],
   "source": [
    "# Parsing structured output\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "list_prompt = PromptTemplate(\n",
    "    template=\"List 100 {item}. {format_instructions} write only the colors, nothing else\",\n",
    "    input_variables=[\"item\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "chain = list_prompt | llm |output_parser\n",
    "result = chain.invoke({\"item\":\"colors\"})\n",
    "print(type(result))\n",
    "print(\"\\nParsed list:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices for Prompt Engineering\n",
    "\n",
    "Here are some best practices for effective prompt engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------\n",
      "Specific Prompt Result:\n",
      "Quantum entanglement - one of the most fascinating and mind-bending concepts in physics. I'd be happy to explain it in simple terms.\n",
      "\n",
      "**What is Quantum Entanglement?**\n",
      "\n",
      "Imagine you have two toy boxes, one in New York and the other in Los Angeles. Each box contains a small ball that can be either red or blue. Now, if you open the box in New York and find a red ball, you would expect the box in Los Angeles to have either a red or blue ball, right? But what if I told you that the moment you open the box in New York and find a red ball, the box in Los Angeles instantly becomes a blue ball, no matter how far apart they are?\n",
      "\n",
      "This is roughly what happens in quantum entanglement. When two particles, like electrons or photons, become \"entangled,\" their properties become connected in a way that can't be explained by classical physics. If something happens to one particle, it instantly affects the other, regardless of the distance between them.\n",
      "\n",
      "**Key Points to Understand:**\n",
      "\n",
      "1. **Entangled particles are connected**: When two particles are entangled, their properties, like spin or energy, become linked.\n",
      "2. **Instant correlation**: If something happens to one particle, it instantly affects the other, even if they're separated by large distances.\n",
      "3. **Non-locality**: This effect happens regardless of the distance between the particles, which seems to defy the idea that information can't travel faster than the speed of light.\n",
      "4. **Randomness**: The state of the particles is random until observed, at which point the correlation becomes apparent.\n",
      "\n",
      "**Analogies to Help You Understand:**\n",
      "\n",
      "1. **Dance partners**: Imagine two dancers performing a choreographed routine. If one dancer spins clockwise, the other dancer will instantly spin counterclockwise, even if they're on opposite sides of the stage.\n",
      "2. **Connected springs**: Picture two springs connected by a invisible thread. If you stretch one spring, the other spring will instantly respond, even if they're separated by a large distance.\n",
      "\n",
      "**Why is Quantum Entanglement Important?**\n",
      "\n",
      "Quantum entanglement has many potential applications, including:\n",
      "\n",
      "1. **Quantum computing**: Entangled particles can be used to perform calculations that are beyond the capabilities of classical computers.\n",
      "2. **Quantum cryptography**: Entangled particles can be used to create secure communication channels, like encrypted messages.\n",
      "3. **Quantum teleportation**: Entangled particles can be used to transfer information from one particle to another, without physical transport of the particles themselves.\n",
      "\n",
      "In summary, quantum entanglement is a phenomenon where two particles become connected in a way that allows them to affect each other instantaneously, regardless of distance. This concept has far-reaching implications for our understanding of the universe and has the potential to revolutionize various fields of science and technology.\n",
      "\n",
      "---------------------------------------------------\n",
      "Few-shot Prompt Result:\n",
      "Sentiment: Neutral\n",
      "\n",
      "The text expresses a lukewarm opinion, using phrases like \"okay\" and \"I guess,\" which indicate a lack of strong emotions or enthusiasm, neither clearly positive nor negative.\n",
      "\n",
      "---------------------------------------------------\n",
      "Step-by-step Prompt Result:\n",
      "To solve the problem 'Calculate the area of a circle with radius 5 cm', I will follow the given steps:\n",
      "\n",
      "1. **Identify the key information**: The key information in this problem is the radius of the circle, which is given as 5 cm.\n",
      "\n",
      "2. **Determine the appropriate formula or method**: The formula to calculate the area of a circle is given by A = πr^2, where A is the area and r is the radius of the circle.\n",
      "\n",
      "3. **Apply the formula or method step-by-step**: \n",
      "   - The radius (r) of the circle is 5 cm.\n",
      "   - The formula for the area (A) of a circle is A = πr^2.\n",
      "   - Substituting the value of r into the formula: A = π(5)^2.\n",
      "   - Calculate the square of the radius: (5)^2 = 25.\n",
      "   - Now, substitute this value back into the formula: A = π * 25.\n",
      "   - Since π is approximately 3.14159, we can calculate the area: A ≈ 3.14159 * 25.\n",
      "   - Perform the multiplication: A ≈ 78.53975.\n",
      "\n",
      "4. **Check your answer**: \n",
      "   - The calculated area is approximately 78.54 square cm (rounded to two decimal places).\n",
      "   - This seems reasonable given the radius of 5 cm, as the area of a circle increases with the square of its radius.\n",
      "\n",
      "Therefore, the area of the circle with a radius of 5 cm is approximately 78.54 square cm.\n"
     ]
    }
   ],
   "source": [
    "# 1. Be specific and provide context\n",
    "specific_prompt = PromptTemplate(\n",
    "    template=\"You are an expert in {field}. Explain {concept} in simple terms for a beginner.\",\n",
    "    input_variables=[\"field\", \"concept\"]\n",
    ")\n",
    "\n",
    "# 2. Use examples (few-shot learning)\n",
    "few_shot_prompt = PromptTemplate(\n",
    "    template=\"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
    "\n",
    "Example 1:\n",
    "Text: I love this product!\n",
    "Sentiment: Positive\n",
    "\n",
    "Example 2:\n",
    "Text: This is the worst experience ever.\n",
    "Sentiment: Negative\n",
    "\n",
    "Example 3:\n",
    "Text: The weather is cloudy today.\n",
    "Sentiment: Neutral\n",
    "\n",
    "Now, classify the following text:\n",
    "Text: {text}\n",
    "Sentiment:\"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# 3. Break complex tasks into steps\n",
    "step_prompt = PromptTemplate(\n",
    "    template=\"\"\"To solve the problem '{problem}', follow these steps:\n",
    "1. Identify the key information\n",
    "2. Determine the appropriate formula or method\n",
    "3. Apply the formula or method step-by-step\n",
    "4. Check your answer\n",
    "\n",
    "Now, solve the problem:\"\"\",\n",
    "    input_variables=[\"problem\"]\n",
    ")\n",
    "\n",
    "# Test the prompts\n",
    "chains = {\n",
    "    \"Specific\": specific_prompt | llm,\n",
    "    \"Few-shot\": few_shot_prompt | llm,\n",
    "    \"Step-by-step\": step_prompt | llm \n",
    "    }\n",
    "\n",
    "for name, chain in chains.items():\n",
    "    print(f\"\\n---------------------------------------------------\\n{name} Prompt Result:\")\n",
    "    if name == \"Specific\":\n",
    "        print(chain.invoke({\"field\":\"physics\", \"concept\":\"quantum entanglement\"}).content)\n",
    "    elif name == \"Few-shot\":\n",
    "        print(chain.invoke({\"text\":\"This movie was okay, I guess.\"}).content)\n",
    "    else:\n",
    "        print(chain.invoke({\"problem\":\"Calculate the area of a circle with radius 5 cm\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've explored various aspects of working with language models in LangChain, including connecting to models, creating prompt templates, building chains, handling responses, and implementing best practices for prompt engineering. These skills will serve as a foundation for building more complex applications with LangChain in future tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
